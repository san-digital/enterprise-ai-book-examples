{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac772ebc-b35b-48ad-9521-879ba3f7c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Chapter 4 Part 2: Fine-Tuning\n",
       "\n",
       "This section walks you through generating an example fine tuned model for use in a \"Biscuit selector\" app.\n",
       "\n",
       "**Goal**: Teach the LLM model your biscuit preferences with a number of examples. And improve the model over time\n",
       "\n",
       "The training set has been generated with the following assumption\n",
       "- Tired = chocolate.\n",
       "- Bored = novelty, maybe jammy dodger or tunnock tea cake.\n",
       "- Sad = fancy biscuit.\n",
       "- Hungry = substantial high calorie, hobnob.\n",
       "\n",
       "The training set is found in \"chapter-4/resources/biscuit_selector.jsonl\". Some example seed data has been provided, but using the app your preferences can be\n",
       "updated over time.\n",
       "\n",
       "Once model is generated, run the biscuit selection app to test the fine tuned model.\n",
       "```sh\n",
       "cd ../chapter-4/biscuit-selector-app/\n",
       "yarn \n",
       "yarn dev\n",
       "```\n",
       "\n",
       "Within the app, recommendation preferences can be logged and used to update the model. So the model learns your preferences without them being explicitly defined.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown('''# Chapter 4 Part 2: Fine-Tuning\n",
    "\n",
    "This section walks you through generating an example fine tuned model for use in a \"Biscuit selector\" app.\n",
    "\n",
    "**Goal**: Teach the LLM model your biscuit preferences with a number of examples. And improve the model over time\n",
    "\n",
    "The training set has been generated with the following assumption\n",
    "- Tired = chocolate.\n",
    "- Bored = novelty, maybe jammy dodger or tunnock tea cake.\n",
    "- Sad = fancy biscuit.\n",
    "- Hungry = substantial high calorie, hobnob.\n",
    "\n",
    "The training set is found in \"chapter-4/resources/biscuit_selector.jsonl\". Some example seed data has been provided, but using the app your preferences can be\n",
    "updated over time.\n",
    "\n",
    "Once model is generated, run the biscuit selection app to test the fine tuned model.\n",
    "```sh\n",
    "cd ../chapter-4/biscuit-selector-app/\n",
    "yarn \n",
    "yarn dev\n",
    "```\n",
    "\n",
    "Within the app, recommendation preferences can be logged and used to update the model. So the model learns your preferences without them being explicitly defined.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e75f47-ce3b-465d-8ebd-6d670835a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training file...\n",
      "File uploaded: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "Starting fine-tuning job...\n",
      "Fine-tune job started: ftjob-SWhshuDQxF74699LH7zowyCE\n",
      "Started job\n",
      "ftjob-SWhshuDQxF74699LH7zowyCE\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # This loads variables from .env into os.environ\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # or: openai.api_key = \"sk-...\"\n",
    "\n",
    "def upload_training_file(file_path: str):\n",
    "    print(\"Uploading training file...\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        response = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "    print(f\"File uploaded: {response.id}\")\n",
    "    return response.id\n",
    "\n",
    "def start_fine_tune(file_id: str, model=\"gpt-4.1-mini-2025-04-14\"):\n",
    "    print(\"Starting fine-tuning job...\")\n",
    "    response = openai.fine_tuning.jobs.create(training_file=file_id, model=model)\n",
    "    print(f\"Fine-tune job started: {response.id}\")\n",
    "    return response.id\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":     # ⬅ Intermediate file\n",
    "\n",
    "    file_id = upload_training_file(\"chapter-4/resources/biscuit_selector.jsonl\")\n",
    "    job_id = start_fine_tune(file_id)\n",
    "    print(\"Started job\")\n",
    "    print(job_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691d2c2-5db7-4aba-972a-8573c8a8117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Waiting for fine-tuning job to complete...\n",
      "\n",
      "[1] Elapsed: 0:00:00 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    [event @ 2025-07-29 10:59:47] Created fine-tuning job: ftjob-SWhshuDQxF74699LH7zowyCE\n",
      "    [event @ 2025-07-29 10:59:47] Validating training file: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[2] Elapsed: 0:00:31 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[3] Elapsed: 0:01:01 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[4] Elapsed: 0:01:34 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[5] Elapsed: 0:02:05 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[6] Elapsed: 0:02:36 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[7] Elapsed: 0:03:06 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[8] Elapsed: 0:03:37 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[9] Elapsed: 0:04:08 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[10] Elapsed: 0:04:38 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[11] Elapsed: 0:05:09 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[12] Elapsed: 0:05:39 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[13] Elapsed: 0:06:10 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[14] Elapsed: 0:06:41 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[15] Elapsed: 0:07:11 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[16] Elapsed: 0:07:42 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[17] Elapsed: 0:08:13 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[18] Elapsed: 0:08:43 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[19] Elapsed: 0:09:14 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[20] Elapsed: 0:09:45 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[21] Elapsed: 0:10:15 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[22] Elapsed: 0:10:46 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[23] Elapsed: 0:11:16 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[24] Elapsed: 0:11:47 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[25] Elapsed: 0:12:18 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[26] Elapsed: 0:12:48 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[27] Elapsed: 0:13:19 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[28] Elapsed: 0:13:50 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[29] Elapsed: 0:14:20 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[30] Elapsed: 0:14:51 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[31] Elapsed: 0:15:21 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[32] Elapsed: 0:15:52 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[33] Elapsed: 0:16:23 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[34] Elapsed: 0:16:53 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[35] Elapsed: 0:17:24 | Status: validating_files\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "[36] Elapsed: 0:17:55 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:17:55] Files validated, moving job to queued state\n",
      "    [event @ 2025-07-29 11:17:57] Fine-tuning job started\n",
      "[37] Elapsed: 0:18:25 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[38] Elapsed: 0:18:56 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[39] Elapsed: 0:19:26 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[40] Elapsed: 0:19:57 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[41] Elapsed: 0:20:28 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:20:19] Step 1/324: training loss=1.76\n",
      "    [event @ 2025-07-29 11:20:20] Step 2/324: training loss=5.30\n",
      "    [event @ 2025-07-29 11:20:31] Step 3/324: training loss=2.96\n",
      "[42] Elapsed: 0:20:58 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:20:32] Step 4/324: training loss=1.57\n",
      "    [event @ 2025-07-29 11:20:32] Step 5/324: training loss=4.40\n",
      "    [event @ 2025-07-29 11:20:37] Step 6/324: training loss=3.85\n",
      "    [event @ 2025-07-29 11:20:38] Step 7/324: training loss=0.71\n",
      "    [event @ 2025-07-29 11:20:38] Step 8/324: training loss=3.90\n",
      "    [event @ 2025-07-29 11:20:38] Step 9/324: training loss=3.10\n",
      "    [event @ 2025-07-29 11:20:38] Step 10/324: training loss=0.72\n",
      "    [event @ 2025-07-29 11:20:39] Step 11/324: training loss=2.07\n",
      "    [event @ 2025-07-29 11:20:46] Step 12/324: training loss=1.33\n",
      "    [event @ 2025-07-29 11:20:46] Step 13/324: training loss=1.26\n",
      "    [event @ 2025-07-29 11:20:46] Step 14/324: training loss=0.30\n",
      "    [event @ 2025-07-29 11:20:46] Step 15/324: training loss=1.17\n",
      "    [event @ 2025-07-29 11:20:46] Step 16/324: training loss=1.29\n",
      "    [event @ 2025-07-29 11:20:46] Step 17/324: training loss=0.77\n",
      "    [event @ 2025-07-29 11:20:46] Step 18/324: training loss=0.65\n",
      "    [event @ 2025-07-29 11:20:46] Step 19/324: training loss=0.93\n",
      "    [event @ 2025-07-29 11:20:46] Step 20/324: training loss=2.60\n",
      "    [event @ 2025-07-29 11:20:53] Step 21/324: training loss=0.61\n",
      "    [event @ 2025-07-29 11:20:53] Step 22/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:20:53] Step 23/324: training loss=0.67\n",
      "    [event @ 2025-07-29 11:20:53] Step 24/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:20:53] Step 25/324: training loss=0.07\n",
      "    [event @ 2025-07-29 11:20:53] Step 26/324: training loss=0.75\n",
      "    [event @ 2025-07-29 11:20:53] Step 27/324: training loss=1.81\n",
      "    [event @ 2025-07-29 11:20:53] Step 28/324: training loss=1.17\n",
      "    [event @ 2025-07-29 11:20:59] Step 29/324: training loss=4.91\n",
      "[43] Elapsed: 0:21:29 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:21:00] Step 30/324: training loss=3.19\n",
      "    [event @ 2025-07-29 11:21:00] Step 31/324: training loss=1.06\n",
      "    [event @ 2025-07-29 11:21:00] Step 32/324: training loss=1.58\n",
      "    [event @ 2025-07-29 11:21:00] Step 33/324: training loss=1.34\n",
      "    [event @ 2025-07-29 11:21:00] Step 34/324: training loss=2.32\n",
      "    [event @ 2025-07-29 11:21:06] Step 35/324: training loss=5.94\n",
      "    [event @ 2025-07-29 11:21:07] Step 36/324: training loss=0.11\n",
      "    [event @ 2025-07-29 11:21:07] Step 37/324: training loss=2.41\n",
      "    [event @ 2025-07-29 11:21:07] Step 38/324: training loss=0.87\n",
      "    [event @ 2025-07-29 11:21:07] Step 39/324: training loss=2.20\n",
      "    [event @ 2025-07-29 11:21:07] Step 40/324: training loss=1.09\n",
      "    [event @ 2025-07-29 11:21:07] Step 41/324: training loss=0.54\n",
      "    [event @ 2025-07-29 11:21:13] Step 42/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:21:14] Step 43/324: training loss=4.71\n",
      "    [event @ 2025-07-29 11:21:14] Step 44/324: training loss=3.77\n",
      "    [event @ 2025-07-29 11:21:14] Step 45/324: training loss=1.17\n",
      "    [event @ 2025-07-29 11:21:14] Step 46/324: training loss=0.47\n",
      "    [event @ 2025-07-29 11:21:14] Step 47/324: training loss=0.47\n",
      "    [event @ 2025-07-29 11:21:14] Step 48/324: training loss=1.93\n",
      "    [event @ 2025-07-29 11:21:14] Step 49/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:21:20] Step 50/324: training loss=1.29\n",
      "    [event @ 2025-07-29 11:21:22] Step 51/324: training loss=1.35\n",
      "    [event @ 2025-07-29 11:21:22] Step 52/324: training loss=1.02\n",
      "    [event @ 2025-07-29 11:21:22] Step 53/324: training loss=1.15\n",
      "    [event @ 2025-07-29 11:21:22] Step 54/324: training loss=0.82\n",
      "    [event @ 2025-07-29 11:21:22] Step 55/324: training loss=0.71\n",
      "    [event @ 2025-07-29 11:21:22] Step 56/324: training loss=1.34\n",
      "    [event @ 2025-07-29 11:21:22] Step 57/324: training loss=0.59\n",
      "    [event @ 2025-07-29 11:21:22] Step 58/324: training loss=2.39\n",
      "    [event @ 2025-07-29 11:21:27] Step 59/324: training loss=1.74\n",
      "[44] Elapsed: 0:22:00 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:21:28] Step 60/324: training loss=0.71\n",
      "    [event @ 2025-07-29 11:21:29] Step 61/324: training loss=1.62\n",
      "    [event @ 2025-07-29 11:21:29] Step 62/324: training loss=0.46\n",
      "    [event @ 2025-07-29 11:21:29] Step 63/324: training loss=0.23\n",
      "    [event @ 2025-07-29 11:21:29] Step 64/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:21:29] Step 65/324: training loss=4.64\n",
      "    [event @ 2025-07-29 11:21:29] Step 66/324: training loss=0.70\n",
      "    [event @ 2025-07-29 11:21:34] Step 67/324: training loss=2.21\n",
      "    [event @ 2025-07-29 11:21:35] Step 68/324: training loss=0.84\n",
      "    [event @ 2025-07-29 11:21:35] Step 69/324: training loss=0.84\n",
      "    [event @ 2025-07-29 11:21:35] Step 70/324: training loss=0.27\n",
      "    [event @ 2025-07-29 11:21:36] Step 71/324: training loss=1.35\n",
      "    [event @ 2025-07-29 11:21:36] Step 72/324: training loss=0.72\n",
      "    [event @ 2025-07-29 11:21:36] Step 73/324: training loss=1.44\n",
      "    [event @ 2025-07-29 11:21:41] Step 74/324: training loss=0.68\n",
      "    [event @ 2025-07-29 11:21:42] Step 75/324: training loss=0.83\n",
      "    [event @ 2025-07-29 11:21:42] Step 76/324: training loss=0.74\n",
      "    [event @ 2025-07-29 11:21:42] Step 77/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:21:42] Step 78/324: training loss=0.48\n",
      "    [event @ 2025-07-29 11:21:42] Step 79/324: training loss=0.28\n",
      "    [event @ 2025-07-29 11:21:42] Step 80/324: training loss=0.42\n",
      "    [event @ 2025-07-29 11:21:43] Step 81/324: training loss=0.32\n",
      "    [event @ 2025-07-29 11:21:48] Step 82/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:21:49] Step 83/324: training loss=0.22\n",
      "    [event @ 2025-07-29 11:21:49] Step 84/324: training loss=0.52\n",
      "    [event @ 2025-07-29 11:21:49] Step 85/324: training loss=0.57\n",
      "    [event @ 2025-07-29 11:21:49] Step 86/324: training loss=0.17\n",
      "    [event @ 2025-07-29 11:21:49] Step 87/324: training loss=2.09\n",
      "    [event @ 2025-07-29 11:21:49] Step 88/324: training loss=1.69\n",
      "    [event @ 2025-07-29 11:21:49] Step 89/324: training loss=1.09\n",
      "    [event @ 2025-07-29 11:21:56] Step 90/324: training loss=0.86\n",
      "    [event @ 2025-07-29 11:21:57] Step 91/324: training loss=0.42\n",
      "    [event @ 2025-07-29 11:21:57] Step 92/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:21:57] Step 93/324: training loss=6.89\n",
      "    [event @ 2025-07-29 11:21:57] Step 94/324: training loss=2.01\n",
      "    [event @ 2025-07-29 11:21:57] Step 95/324: training loss=1.05\n",
      "    [event @ 2025-07-29 11:21:57] Step 96/324: training loss=1.86\n",
      "    [event @ 2025-07-29 11:21:57] Step 97/324: training loss=1.10\n",
      "    [event @ 2025-07-29 11:21:57] Step 98/324: training loss=0.72\n",
      "    [event @ 2025-07-29 11:22:03] Step 99/324: training loss=1.56\n",
      "[45] Elapsed: 0:22:31 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:22:04] Step 100/324: training loss=0.33\n",
      "    [event @ 2025-07-29 11:22:04] Step 101/324: training loss=0.41\n",
      "    [event @ 2025-07-29 11:22:04] Step 102/324: training loss=0.42\n",
      "    [event @ 2025-07-29 11:22:04] Step 103/324: training loss=1.33\n",
      "    [event @ 2025-07-29 11:22:04] Step 104/324: training loss=0.13\n",
      "    [event @ 2025-07-29 11:22:04] Step 105/324: training loss=1.10\n",
      "    [event @ 2025-07-29 11:22:04] Step 106/324: training loss=0.29\n",
      "    [event @ 2025-07-29 11:22:10] Step 107/324: training loss=1.11\n",
      "    [event @ 2025-07-29 11:22:11] Step 108/324: training loss=0.35\n",
      "    [event @ 2025-07-29 11:22:18] Step 109/324: training loss=0.77\n",
      "    [event @ 2025-07-29 11:22:18] Step 110/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:22:19] Step 111/324: training loss=0.24\n",
      "    [event @ 2025-07-29 11:22:19] Step 112/324: training loss=0.29\n",
      "    [event @ 2025-07-29 11:22:19] Step 113/324: training loss=0.75\n",
      "    [event @ 2025-07-29 11:22:19] Step 114/324: training loss=0.70\n",
      "    [event @ 2025-07-29 11:22:19] Step 115/324: training loss=1.23\n",
      "    [event @ 2025-07-29 11:22:19] Step 116/324: training loss=0.76\n",
      "    [event @ 2025-07-29 11:22:19] Step 117/324: training loss=0.52\n",
      "    [event @ 2025-07-29 11:22:25] Step 118/324: training loss=1.08\n",
      "    [event @ 2025-07-29 11:22:25] Step 119/324: training loss=0.16\n",
      "    [event @ 2025-07-29 11:22:25] Step 120/324: training loss=1.46\n",
      "    [event @ 2025-07-29 11:22:26] Step 121/324: training loss=1.11\n",
      "    [event @ 2025-07-29 11:22:27] Step 122/324: training loss=0.95\n",
      "    [event @ 2025-07-29 11:22:27] Step 123/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:22:27] Step 124/324: training loss=0.46\n",
      "    [event @ 2025-07-29 11:22:27] Step 125/324: training loss=0.08\n",
      "    [event @ 2025-07-29 11:22:33] Step 126/324: training loss=0.49\n",
      "[46] Elapsed: 0:23:01 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:22:34] Step 127/324: training loss=0.06\n",
      "    [event @ 2025-07-29 11:22:34] Step 128/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:22:34] Step 129/324: training loss=0.41\n",
      "    [event @ 2025-07-29 11:22:34] Step 130/324: training loss=0.93\n",
      "    [event @ 2025-07-29 11:22:34] Step 131/324: training loss=0.39\n",
      "    [event @ 2025-07-29 11:22:34] Step 132/324: training loss=0.58\n",
      "    [event @ 2025-07-29 11:22:34] Step 133/324: training loss=0.53\n",
      "    [event @ 2025-07-29 11:22:34] Step 134/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:22:40] Step 135/324: training loss=0.06\n",
      "    [event @ 2025-07-29 11:22:41] Step 136/324: training loss=0.03\n",
      "    [event @ 2025-07-29 11:22:41] Step 137/324: training loss=0.34\n",
      "    [event @ 2025-07-29 11:22:41] Step 138/324: training loss=0.28\n",
      "    [event @ 2025-07-29 11:22:41] Step 139/324: training loss=1.36\n",
      "    [event @ 2025-07-29 11:22:41] Step 140/324: training loss=1.25\n",
      "    [event @ 2025-07-29 11:22:41] Step 141/324: training loss=0.95\n",
      "    [event @ 2025-07-29 11:22:41] Step 142/324: training loss=1.82\n",
      "    [event @ 2025-07-29 11:22:47] Step 143/324: training loss=0.37\n",
      "    [event @ 2025-07-29 11:22:48] Step 144/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:22:48] Step 145/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:22:48] Step 146/324: training loss=0.37\n",
      "    [event @ 2025-07-29 11:22:48] Step 147/324: training loss=1.55\n",
      "    [event @ 2025-07-29 11:22:48] Step 148/324: training loss=0.06\n",
      "    [event @ 2025-07-29 11:22:48] Step 149/324: training loss=0.80\n",
      "    [event @ 2025-07-29 11:22:48] Step 150/324: training loss=0.61\n",
      "    [event @ 2025-07-29 11:22:54] Step 151/324: training loss=0.52\n",
      "    [event @ 2025-07-29 11:22:55] Step 152/324: training loss=0.04\n",
      "    [event @ 2025-07-29 11:22:55] Step 153/324: training loss=1.17\n",
      "    [event @ 2025-07-29 11:22:55] Step 154/324: training loss=0.07\n",
      "    [event @ 2025-07-29 11:22:55] Step 155/324: training loss=0.53\n",
      "    [event @ 2025-07-29 11:22:55] Step 156/324: training loss=0.01\n",
      "    [event @ 2025-07-29 11:22:55] Step 157/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:22:55] Step 158/324: training loss=0.16\n",
      "    [event @ 2025-07-29 11:23:01] Step 159/324: training loss=1.13\n",
      "[47] Elapsed: 0:23:32 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:23:02] Step 160/324: training loss=0.76\n",
      "    [event @ 2025-07-29 11:23:03] Step 161/324: training loss=0.76\n",
      "    [event @ 2025-07-29 11:23:03] Step 162/324: training loss=0.56\n",
      "    [event @ 2025-07-29 11:23:03] Step 163/324: training loss=0.31\n",
      "    [event @ 2025-07-29 11:23:03] Step 164/324: training loss=1.37\n",
      "    [event @ 2025-07-29 11:23:03] Step 165/324: training loss=6.90\n",
      "    [event @ 2025-07-29 11:23:03] Step 166/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:23:03] Step 167/324: training loss=0.04\n",
      "    [event @ 2025-07-29 11:23:08] Step 168/324: training loss=0.34\n",
      "    [event @ 2025-07-29 11:23:09] Step 169/324: training loss=0.20\n",
      "    [event @ 2025-07-29 11:23:09] Step 170/324: training loss=0.28\n",
      "    [event @ 2025-07-29 11:23:10] Step 171/324: training loss=1.11\n",
      "    [event @ 2025-07-29 11:23:10] Step 172/324: training loss=1.26\n",
      "    [event @ 2025-07-29 11:23:10] Step 173/324: training loss=0.24\n",
      "    [event @ 2025-07-29 11:23:10] Step 174/324: training loss=0.46\n",
      "    [event @ 2025-07-29 11:23:10] Step 175/324: training loss=0.50\n",
      "    [event @ 2025-07-29 11:23:15] Step 176/324: training loss=0.67\n",
      "    [event @ 2025-07-29 11:23:16] Step 177/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:23:16] Step 178/324: training loss=0.31\n",
      "    [event @ 2025-07-29 11:23:16] Step 179/324: training loss=0.50\n",
      "    [event @ 2025-07-29 11:23:16] Step 180/324: training loss=0.04\n",
      "    [event @ 2025-07-29 11:23:17] Step 181/324: training loss=0.55\n",
      "    [event @ 2025-07-29 11:23:17] Step 182/324: training loss=0.47\n",
      "    [event @ 2025-07-29 11:23:17] Step 183/324: training loss=0.75\n",
      "    [event @ 2025-07-29 11:23:22] Step 184/324: training loss=0.51\n",
      "    [event @ 2025-07-29 11:23:23] Step 185/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:23:23] Step 186/324: training loss=0.62\n",
      "    [event @ 2025-07-29 11:23:23] Step 187/324: training loss=0.79\n",
      "    [event @ 2025-07-29 11:23:23] Step 188/324: training loss=0.48\n",
      "    [event @ 2025-07-29 11:23:23] Step 189/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:23:23] Step 190/324: training loss=0.40\n",
      "    [event @ 2025-07-29 11:23:24] Step 191/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:23:29] Step 192/324: training loss=0.35\n",
      "[48] Elapsed: 0:24:03 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:23:30] Step 193/324: training loss=0.16\n",
      "    [event @ 2025-07-29 11:23:30] Step 194/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:23:30] Step 195/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:23:30] Step 196/324: training loss=0.80\n",
      "    [event @ 2025-07-29 11:23:30] Step 197/324: training loss=1.35\n",
      "    [event @ 2025-07-29 11:23:30] Step 198/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:23:30] Step 199/324: training loss=0.98\n",
      "    [event @ 2025-07-29 11:23:37] Step 200/324: training loss=0.48\n",
      "    [event @ 2025-07-29 11:23:38] Step 201/324: training loss=0.67\n",
      "    [event @ 2025-07-29 11:23:38] Step 202/324: training loss=0.27\n",
      "    [event @ 2025-07-29 11:23:38] Step 203/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:23:38] Step 204/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:23:38] Step 205/324: training loss=0.16\n",
      "    [event @ 2025-07-29 11:23:38] Step 206/324: training loss=0.47\n",
      "    [event @ 2025-07-29 11:23:38] Step 207/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:23:38] Step 208/324: training loss=0.97\n",
      "    [event @ 2025-07-29 11:23:44] Step 209/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:23:45] Step 210/324: training loss=1.23\n",
      "    [event @ 2025-07-29 11:23:45] Step 211/324: training loss=0.54\n",
      "    [event @ 2025-07-29 11:23:45] Step 212/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:23:45] Step 213/324: training loss=0.14\n",
      "    [event @ 2025-07-29 11:23:45] Step 214/324: training loss=0.51\n",
      "    [event @ 2025-07-29 11:23:45] Step 215/324: training loss=0.13\n",
      "    [event @ 2025-07-29 11:23:45] Step 216/324: training loss=0.58\n",
      "    [event @ 2025-07-29 11:23:52] Step 217/324: training loss=0.92\n",
      "    [event @ 2025-07-29 11:23:53] Step 218/324: training loss=0.46\n",
      "    [event @ 2025-07-29 11:23:53] Step 219/324: training loss=1.44\n",
      "    [event @ 2025-07-29 11:23:53] Step 220/324: training loss=0.03\n",
      "    [event @ 2025-07-29 11:23:59] Step 221/324: training loss=0.67\n",
      "    [event @ 2025-07-29 11:24:00] Step 222/324: training loss=0.54\n",
      "    [event @ 2025-07-29 11:24:00] Step 223/324: training loss=0.50\n",
      "    [event @ 2025-07-29 11:24:00] Step 224/324: training loss=0.10\n",
      "    [event @ 2025-07-29 11:24:00] Step 225/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:00] Step 226/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:24:00] Step 227/324: training loss=0.06\n",
      "    [event @ 2025-07-29 11:24:00] Step 228/324: training loss=0.03\n",
      "    [event @ 2025-07-29 11:24:00] Step 229/324: training loss=0.41\n",
      "    [event @ 2025-07-29 11:24:05] Step 230/324: training loss=0.27\n",
      "[49] Elapsed: 0:24:34 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:24:07] Step 231/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:24:07] Step 232/324: training loss=0.33\n",
      "    [event @ 2025-07-29 11:24:07] Step 233/324: training loss=0.32\n",
      "    [event @ 2025-07-29 11:24:07] Step 234/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:07] Step 235/324: training loss=1.33\n",
      "    [event @ 2025-07-29 11:24:07] Step 236/324: training loss=0.02\n",
      "    [event @ 2025-07-29 11:24:13] Step 237/324: training loss=0.93\n",
      "    [event @ 2025-07-29 11:24:14] Step 238/324: training loss=1.60\n",
      "    [event @ 2025-07-29 11:24:14] Step 239/324: training loss=0.02\n",
      "    [event @ 2025-07-29 11:24:14] Step 240/324: training loss=0.34\n",
      "    [event @ 2025-07-29 11:24:15] Step 241/324: training loss=0.01\n",
      "    [event @ 2025-07-29 11:24:15] Step 242/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:15] Step 243/324: training loss=1.76\n",
      "    [event @ 2025-07-29 11:24:15] Step 244/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:15] Step 245/324: training loss=0.24\n",
      "    [event @ 2025-07-29 11:24:15] Step 246/324: training loss=0.29\n",
      "    [event @ 2025-07-29 11:24:20] Step 247/324: training loss=0.27\n",
      "    [event @ 2025-07-29 11:24:21] Step 248/324: training loss=0.65\n",
      "    [event @ 2025-07-29 11:24:21] Step 249/324: training loss=0.55\n",
      "    [event @ 2025-07-29 11:24:21] Step 250/324: training loss=0.13\n",
      "    [event @ 2025-07-29 11:24:22] Step 251/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:22] Step 252/324: training loss=0.05\n",
      "    [event @ 2025-07-29 11:24:22] Step 253/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:22] Step 254/324: training loss=0.77\n",
      "    [event @ 2025-07-29 11:24:27] Step 255/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:24:30] Step 256/324: training loss=0.65\n",
      "    [event @ 2025-07-29 11:24:30] Step 257/324: training loss=0.65\n",
      "    [event @ 2025-07-29 11:24:30] Step 258/324: training loss=4.72\n",
      "    [event @ 2025-07-29 11:24:30] Step 259/324: training loss=0.94\n",
      "    [event @ 2025-07-29 11:24:30] Step 260/324: training loss=2.28\n",
      "    [event @ 2025-07-29 11:24:30] Step 261/324: training loss=0.39\n",
      "    [event @ 2025-07-29 11:24:30] Step 262/324: training loss=0.29\n",
      "    [event @ 2025-07-29 11:24:36] Step 263/324: training loss=0.27\n",
      "[50] Elapsed: 0:25:05 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:24:37] Step 264/324: training loss=0.91\n",
      "    [event @ 2025-07-29 11:24:37] Step 265/324: training loss=2.03\n",
      "    [event @ 2025-07-29 11:24:37] Step 266/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:24:37] Step 267/324: training loss=1.67\n",
      "    [event @ 2025-07-29 11:24:37] Step 268/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:24:37] Step 269/324: training loss=1.28\n",
      "    [event @ 2025-07-29 11:24:37] Step 270/324: training loss=0.46\n",
      "    [event @ 2025-07-29 11:24:37] Step 271/324: training loss=0.07\n",
      "    [event @ 2025-07-29 11:24:37] Step 272/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:24:43] Step 273/324: training loss=0.20\n",
      "    [event @ 2025-07-29 11:24:45] Step 274/324: training loss=0.10\n",
      "    [event @ 2025-07-29 11:24:45] Step 275/324: training loss=0.16\n",
      "    [event @ 2025-07-29 11:24:45] Step 276/324: training loss=1.11\n",
      "    [event @ 2025-07-29 11:24:45] Step 277/324: training loss=0.39\n",
      "    [event @ 2025-07-29 11:24:45] Step 278/324: training loss=0.32\n",
      "    [event @ 2025-07-29 11:24:45] Step 279/324: training loss=0.25\n",
      "    [event @ 2025-07-29 11:24:45] Step 280/324: training loss=0.58\n",
      "    [event @ 2025-07-29 11:24:51] Step 281/324: training loss=0.94\n",
      "    [event @ 2025-07-29 11:24:52] Step 282/324: training loss=0.17\n",
      "    [event @ 2025-07-29 11:24:52] Step 283/324: training loss=0.44\n",
      "    [event @ 2025-07-29 11:24:52] Step 284/324: training loss=0.33\n",
      "    [event @ 2025-07-29 11:24:52] Step 285/324: training loss=0.21\n",
      "    [event @ 2025-07-29 11:24:52] Step 286/324: training loss=0.18\n",
      "    [event @ 2025-07-29 11:24:52] Step 287/324: training loss=1.50\n",
      "    [event @ 2025-07-29 11:24:52] Step 288/324: training loss=0.05\n",
      "    [event @ 2025-07-29 11:24:52] Step 289/324: training loss=0.63\n",
      "    [event @ 2025-07-29 11:24:57] Step 290/324: training loss=0.42\n",
      "    [event @ 2025-07-29 11:24:59] Step 291/324: training loss=0.30\n",
      "    [event @ 2025-07-29 11:24:59] Step 292/324: training loss=0.81\n",
      "    [event @ 2025-07-29 11:24:59] Step 293/324: training loss=0.34\n",
      "    [event @ 2025-07-29 11:24:59] Step 294/324: training loss=0.61\n",
      "    [event @ 2025-07-29 11:24:59] Step 295/324: training loss=0.68\n",
      "    [event @ 2025-07-29 11:24:59] Step 296/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:25:04] Step 297/324: training loss=0.33\n",
      "[51] Elapsed: 0:25:36 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:25:05] Step 298/324: training loss=0.27\n",
      "    [event @ 2025-07-29 11:25:05] Step 299/324: training loss=0.83\n",
      "    [event @ 2025-07-29 11:25:05] Step 300/324: training loss=0.00\n",
      "    [event @ 2025-07-29 11:25:06] Step 301/324: training loss=0.12\n",
      "    [event @ 2025-07-29 11:25:06] Step 302/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:25:06] Step 303/324: training loss=0.38\n",
      "    [event @ 2025-07-29 11:25:06] Step 304/324: training loss=0.51\n",
      "    [event @ 2025-07-29 11:25:11] Step 305/324: training loss=0.24\n",
      "    [event @ 2025-07-29 11:25:12] Step 306/324: training loss=0.23\n",
      "    [event @ 2025-07-29 11:25:12] Step 307/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:25:12] Step 308/324: training loss=0.07\n",
      "    [event @ 2025-07-29 11:25:12] Step 309/324: training loss=0.32\n",
      "    [event @ 2025-07-29 11:25:12] Step 310/324: training loss=0.31\n",
      "    [event @ 2025-07-29 11:25:13] Step 311/324: training loss=0.26\n",
      "    [event @ 2025-07-29 11:25:13] Step 312/324: training loss=0.31\n",
      "    [event @ 2025-07-29 11:25:20] Step 313/324: training loss=0.49\n",
      "    [event @ 2025-07-29 11:25:20] Step 314/324: training loss=0.08\n",
      "    [event @ 2025-07-29 11:25:20] Step 315/324: training loss=0.65\n",
      "    [event @ 2025-07-29 11:25:20] Step 316/324: training loss=1.09\n",
      "    [event @ 2025-07-29 11:25:20] Step 317/324: training loss=0.60\n",
      "    [event @ 2025-07-29 11:25:20] Step 318/324: training loss=0.12\n",
      "    [event @ 2025-07-29 11:25:20] Step 319/324: training loss=0.43\n",
      "    [event @ 2025-07-29 11:25:20] Step 320/324: training loss=0.41\n",
      "    [event @ 2025-07-29 11:25:21] Step 321/324: training loss=0.23\n",
      "    [event @ 2025-07-29 11:25:21] Step 322/324: training loss=0.45\n",
      "    [event @ 2025-07-29 11:25:27] Step 323/324: training loss=0.18\n",
      "[52] Elapsed: 0:26:06 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "    [event @ 2025-07-29 11:25:27] Step 324/324: training loss=0.70\n",
      "    [event @ 2025-07-29 11:25:49] Checkpoint created at step 108\n",
      "    [event @ 2025-07-29 11:25:49] Checkpoint created at step 216\n",
      "    [event @ 2025-07-29 11:25:49] New fine-tuned model created\n",
      "    [event @ 2025-07-29 11:25:49] Evaluating model against our usage policies\n",
      "[53] Elapsed: 0:26:37 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[54] Elapsed: 0:27:08 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[55] Elapsed: 0:27:39 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[56] Elapsed: 0:28:09 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[57] Elapsed: 0:28:40 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[58] Elapsed: 0:29:11 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[59] Elapsed: 0:29:41 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[60] Elapsed: 0:30:12 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[61] Elapsed: 0:30:43 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[62] Elapsed: 0:31:14 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[63] Elapsed: 0:31:44 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[64] Elapsed: 0:32:15 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[65] Elapsed: 0:32:46 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[66] Elapsed: 0:33:17 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[67] Elapsed: 0:33:48 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[68] Elapsed: 0:34:19 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[69] Elapsed: 0:34:49 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[70] Elapsed: 0:35:20 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n",
      "[71] Elapsed: 0:35:52 | Status: running\n",
      "    - Model: gpt-4.1-mini-2025-04-14\n",
      "    - Training File: file-LtXHGRPmqzRGkxA7tzboCY\n",
      "    - Output fine-tuned model name: N/A\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "def save_model_name(model_name: str, output_path: str):\n",
    "    print(f\"Saving fine-tuned model name to {output_path}\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump({\"model\": model_name}, f)\n",
    "    print(\"Model name saved.\")\n",
    "\n",
    "\n",
    "def wait_for_completion(job_id: str, poll_interval=30):\n",
    "    print(\"Waiting for fine-tuning job to complete...\\n\")\n",
    "    start_time = time.time()\n",
    "    seen_event_ids = set()\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        job = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "        elapsed = str(datetime.timedelta(seconds=int(time.time() - start_time)))\n",
    "        step += 1\n",
    "\n",
    "        print(f\"[{step}] Elapsed: {elapsed} | Status: {job.status}\")\n",
    "        print(f\"    - Model: {job.model}\")\n",
    "        print(f\"    - Training File: {job.training_file}\")\n",
    "        if job.validation_file:\n",
    "            print(f\"    - Validation File: {job.validation_file}\")\n",
    "        if job.status == \"running\":\n",
    "            print(f\"    - Output fine-tuned model name: {job.fine_tuned_model or 'N/A'}\")\n",
    "\n",
    "        \n",
    "        try:\n",
    "            events = openai.fine_tuning.jobs.list_events(job_id, limit=50).data\n",
    "            new_events = [e for e in reversed(events) if e.id not in seen_event_ids]\n",
    "            for event in new_events:\n",
    "                seen_event_ids.add(event.id)\n",
    "                ts = datetime.datetime.fromtimestamp(event.created_at).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(f\"    [event @ {ts}] {event.message}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Failed to retrieve events: {e}\")\n",
    "\n",
    "        if job.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "            print(f\"\\nJob {job.status.upper()}\")\n",
    "            return job\n",
    "\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "model_output_path = \"chapter-4/resources/model.json\"\n",
    "\n",
    "result = wait_for_completion(job_id)\n",
    "\n",
    "print(f\"Final status: {result.status}\")\n",
    "if result.status == \"succeeded\" and result.fine_tuned_model:\n",
    "    save_model_name(result.fine_tuned_model, model_output_path)\n",
    "else:\n",
    "    print(\"Fine-tuning failed or no model was produced.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cabb2-992b-444c-b461-5cf02788bdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf04ef-09e0-4649-b103-a0386310f71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
