{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc008c1-1021-4c51-a7a4-586c588fbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_demo.py\n",
    "#\n",
    "# 1. Loads a few sample documents\n",
    "# 2. Embeds them using OpenAI\n",
    "# 3. Stores in FAISS for similarity search\n",
    "# 4. Retrieves relevant chunks for a question\n",
    "# 5. Asks GPT-4 to answer using those chunks\n",
    "#\n",
    "# Prereqs:\n",
    "# pip install openai faiss-cpu python-dotenv\n",
    "# export OPENAI_API_KEY=\"sk-...\"\n",
    "# or use a .env file\n",
    "#\n",
    "# Note: This example omits error handling for simplicity.\n",
    "# In production, you should add proper exception handling for API calls.\n",
    "\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Sample docs\n",
    "documents = [\n",
    "    \"Employees are entitled to 90 days of paid holiday per year, plus bank holidays.\",\n",
    "    \"The company operates a flexible working policy, including remote work options.\",\n",
    "    \"Employees can use the company blimp once per year.\",\n",
    "    \"The IT helpdesk is available from 7am to 7:05am, Mondays only.\",\n",
    "]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Step 1 – Embed documents\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-3-small\" # https://platform.openai.com/docs/models/text-embedding-3-small\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "doc_embeddings = [get_embedding(doc) for doc in documents]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Step 2 – Store the document vectors in an in-memory table, for similarity searches\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "embedding_size = len(doc_embeddings[0])\n",
    "faiss_index = faiss.IndexFlatL2(embedding_size) # Exact L2 index, fine for <10k docs\n",
    "faiss_index.add(np.array(doc_embeddings).astype(\"float32\"))  # Add all document vectors to the index\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Step 3 – Ask a question using RAG\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def retrieve_context(question: str, top_k: int = 2) -> List[str]:\n",
    "    \"\"\"Finds the top_k most relevant documents to the question using vector similarity.\"\"\"\n",
    "    question_vector = np.array(get_embedding(question)).astype(\"float32\")\n",
    "    distances, indices = faiss_index.search(np.array([question_vector]), top_k)\n",
    "    return [documents[i] for i in indices[0]]\n",
    "\n",
    "def ask_with_context(question: str) -> str:\n",
    "    context_chunks = retrieve_context(question)\n",
    "    context = \"\\n\".join(f\"- {chunk}\" for chunk in context_chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful company assistant. Use the context below to answer the user's question.\n",
    "If the answer is not in the context, say \"Sorry, I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957675bf-d933-4b4f-8d2c-2f38f6133e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"How many days holiday do I get?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11780a2c-8443-4cca-83c6-5944e42d1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"How many days holiday do I have if I have used 20 days already\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c73c0-a497-44aa-b839-29f18f3a06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"Can I bring my hamster to work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635fbc9-3fa3-4635-b3e9-b707974b91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"When is the IT helpdesk available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8704a2a-45e4-45ae-ad09-c4ebfc94761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"How long is the IT helpdesk open for?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9576f22-d83e-49de-a12f-164ada3d1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"Can I use the company blimp?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5fa0f-6037-466d-8a2b-cf17976f8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"Can I use the company blimp? I used it yesterday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e83b7-be22-4b03-9ae8-76e6de91a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_context(\"I have used the company blimp 3 times this week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac772ebc-b35b-48ad-9521-879ba3f7c237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
